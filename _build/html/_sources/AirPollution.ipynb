{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "351af570",
   "metadata": {},
   "source": [
    "# Seoul Air Quality Level Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186d6739",
   "metadata": {},
   "source": [
    "## 1. Seoul Air Quality Dataset\n",
    "\n",
    "This dataset is collected from @seoul_air, including Seoul air quality data from 2008 to 2018. Air quality is impacted by many factors such as traffic volume, neighboring area AQ situations, weather, seasonal information, and other economic activities. Many works have addressed the relationship between AQ level and other factors via numerous modeling approaches. For instance, during the Chuseok holidays, the AQI tends to get better, while it is serious during weekdays, especially with foggy weather conditions or in the yellow dust season. You can refer to [3-5] for more information on how researchers used this dataset in their works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ca805e",
   "metadata": {},
   "source": [
    "| Column | Description |\n",
    "|---------|---------|\n",
    "| Datetime | Timestamp |\n",
    "| District | District code 0-25 (Code 0 represents the average value of all 25 districts in Seoul). Other districts are identified from 1 to 25.  The order of district codes is 0 - 평균, 1 - 종로구, 2 - 중구, 3 - 용산구, 4 - 성동구, 5 - 광진구, 6 - 동대문구, 7 - 중랑구, 8 - 성북구, 9 - 강북구, 10 - 도봉구, 11 - 노원구, 12 - 은평구, 13 - 서대문구, 14 - 마포구, 15 - 양천구, 16 - 강서구, 17 - 구로구, 18 - 금천구, 19 - 영등포구, 20 - 동작구, 21 - 관악구, 22 - 서초구, 23 - 강남구, 24 - 송파구, 25 - 강동구 |\n",
    "| PM10_CONC | PM10 concentration (µg/m3) |\n",
    "| PM2_5_CONC | PM2.5 concentration (µg/m3) |\n",
    "|O3         | Ozone concentration (µg/m3) |\n",
    "| NO2 | NO2 concentration (µg/m3) |\n",
    "| CO | CO concentration (µg/m3) |\n",
    "| SO2 | SO2 concentration (µg/m3) |\n",
    "| PM10_AQI | PM10 AQI Index according to US Standard AQI Index |\n",
    "| PM2_5_AQI | PM2.5 AQI Index according to US Standard AQI Index |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0faf02",
   "metadata": {},
   "source": [
    "## 2. Additional Data Sources\n",
    "<figure>\n",
    "<img src=\"./_images/ml_system.png\" alt=\"ml_system\" width=\"80%\" height=\"80%\">\n",
    "<figcaption>Image Source From https://proceedings.neurips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf</figcaption>\n",
    "</figure>\n",
    "\n",
    "As the figure shows, we spend most of the time on data collection, cleansing, and pre-processing. Only a small amount of time is for machine learning model development. To increase the accuracy of models, we must try to find additional data to verify our hypotheses.\n",
    "\n",
    "### 2.1 Weather Data\n",
    "\n",
    "<figure>\n",
    "<img width=\"500px\" src=\"./_images/seoul_weather.png\" alt=\"ml_system\" width=\"80%\" height=\"80%\">\n",
    "<figcaption>Seoul Weather from worldweatheronline.com</figcaption>\n",
    "</figure>\n",
    "\n",
    "Many researches have pointed out that air quality level relates to weather conditions. For instance, AQ levels get better after a heavy rain, or it usually gets worse during the winter season. For more information, please check out reference papers.\n",
    "\n",
    "### 2.2 Holiday Information\n",
    "\n",
    "<figure>\n",
    "<img width=\"500px\" src=\"./_images/holiday.png\" alt=\"ml_system\" width=\"80%\" height=\"80%\">\n",
    "<figcaption>Seoul Holidays from timeanddata.com</figcaption>\n",
    "</figure>\n",
    "\n",
    "Similar to weather data, we can collect holiday information from websites like timeanddata.com."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7260356",
   "metadata": {},
   "source": [
    "## 3. Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0db937d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117caf60",
   "metadata": {},
   "source": [
    "### 3.1 Data loading\n",
    "\n",
    "As the original Seoul AQ dataset contains 25 information of 25 districts, it's too large for this example. Therefore, we only work with the overall AQ dataset only. In short, we extract city-level air quality data from 2014 -> 2018 from the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b37116fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/alexbui/workspace/HandbookForDatascience/notebooks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f1b0645",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/alexbui/workspace/HandbookForDatascience/notebooks/data/seoul_air_avg.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-082d923606f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseoul_air\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'data/seoul_air_avg.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mseoul_air\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PM10_AQI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"PM2_5_AQI\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mseoul_air\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseoul_air\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/alexbui/workspace/HandbookForDatascience/notebooks/data/seoul_air_avg.csv'"
     ]
    }
   ],
   "source": [
    "seoul_air = pd.read_csv(path + 'data/seoul_air_avg.csv')\n",
    "seoul_air.drop([\"PM10_AQI\", \"PM2_5_AQI\"], axis=1, inplace=True)\n",
    "seoul_air.columns = [c.lower() for c in seoul_air.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97f2062",
   "metadata": {},
   "outputs": [],
   "source": [
    "seoul_air"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bf36d1",
   "metadata": {},
   "source": [
    "***Load weather data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feddb990",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv(path + \"data/weather_forecasts.csv\")\n",
    "weather = weather[weather['datetime'] <= \"2018-06-18 11:00:00\"]\n",
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc81469",
   "metadata": {},
   "source": [
    "### 3.2 Check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad2c5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6771aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in seoul_air.columns:\n",
    "    print(c, seoul_air[c].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbe85dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in weather.columns:\n",
    "    print(c, weather[c].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cfa321",
   "metadata": {},
   "source": [
    "### 3.3 Check outlier values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a100c182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_outliners(seoul_air, c):\n",
    "    col = seoul_air.loc[:,c]\n",
    "    abs_skew = col.skew()\n",
    "    mean_v = col.mean()\n",
    "    median_v = col.median()\n",
    "    q3 = np.nanpercentile(col, 75)\n",
    "    q1 = np.nanpercentile(col, 25)\n",
    "    iqr = (q3 - q1) * 1.5\n",
    "    ceiling = iqr + q3\n",
    "    # floor = q1 - iqr \n",
    "    # col[(col > ceiling) | (col < floor)]\n",
    "    print(\"num of outlier\", c, col[col > ceiling].count())\n",
    "    if abs_skew > 1:\n",
    "        col[col > ceiling] = median_v\n",
    "    else:\n",
    "        col[col > ceiling] = mean_v    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfd9120",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"temperature(C)\",\t\"feel_like(C)\",\t\"wind_speed(km/h)\",\t\"wind_gust(km/h)\", \"cloud(%)\", \"humidity(%)\", \"rain(mm)\", \"pressure\"]:\n",
    "    check_outliners(weather, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9550bd1",
   "metadata": {},
   "source": [
    "### 3.4 Merge Air Data & Weather Data\n",
    "\n",
    "We have to check which datetime data is missing and interpolate it. The simplest way is to filling it with near by neighbors or average values of near by neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba7e530",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_weather = pd.merge(weather, seoul_air, on='datetime', how='outer')\n",
    "air_weather[air_weather['pm10_conc'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413eb569",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_weather2 = air_weather.interpolate(method='linear')\n",
    "air_weather2[air_weather['pm10_conc'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edd2de0",
   "metadata": {},
   "source": [
    "### 3.5 Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d7f96",
   "metadata": {},
   "source": [
    "***Plot correlation to first understand feature interactions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b78e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = seoul_air.iloc[:,1:7].corr()\n",
    "fix, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(corr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d3d550",
   "metadata": {},
   "source": [
    "***Align 1h to check correlation with previous hour***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1831f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_dataframe(df, timeshift=1):\n",
    "    df1 = df.iloc[:-timeshift,:]\n",
    "    df1.columns = [c + \"_m%i\" % timeshift for c in df1.columns]\n",
    "    df2 = df.iloc[timeshift:,:].reset_index().drop([\"index\"],axis=1)\n",
    "    return pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b028d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr(df):\n",
    "    align_corr = df.corr()\n",
    "    plt.subplots(figsize=(10,10))\n",
    "    sns.heatmap(align_corr)\n",
    "    plt.show()\n",
    "    return align_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f1ad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "align1 = concat_dataframe(seoul_air.iloc[:,1:7], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbfd16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_corr(align1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b041a652",
   "metadata": {},
   "source": [
    "***Align 4h to check correlation with 4 hours ago***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776454af",
   "metadata": {},
   "outputs": [],
   "source": [
    "align4 = concat_dataframe(seoul_air.iloc[:,1:7], 4)\n",
    "plot_corr(align4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c041607c",
   "metadata": {},
   "source": [
    "***Plot weather & air quality together***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75917ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_corr(air_weather2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d0abbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_weather4 = concat_dataframe(air_weather2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6285f07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_corr(air_weather4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b798f4fe",
   "metadata": {},
   "source": [
    "### 3.6 Training, Testing Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445b2378",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['pm2_5_conc', 'pm10_conc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b682ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(timeshift=1):\n",
    "    drp_columns = ['datetime', 'datetime_m%i'%timeshift, 'weather_m%i'%timeshift, 'wind_direction_m%i'%timeshift, 'weather', 'wind_direction']\n",
    "    dataset1 = concat_dataframe(air_weather2, timeshift)\n",
    "    training1 = dataset1[dataset1['datetime'] <= \"2016-12-31 23:00:00\"]\n",
    "    training1.drop(drp_columns, axis=1, inplace=True)\n",
    "    testing1 = dataset1[(dataset1['datetime'] > \"2016-12-31 23:00:00\") & (dataset1['datetime'] <= \"2017-12-31 23:00:00\")]\n",
    "    testing1.drop(drp_columns, axis=1, inplace=True)\n",
    "    X1_train, y1_train = training1.drop(target, axis=1), training1['pm2_5_conc']\n",
    "    X1_test, y1_test = testing1.drop(target, axis=1), testing1['pm2_5_conc']\n",
    "    return X1_train, y1_train, X1_test, y1_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970ec47c",
   "metadata": {},
   "source": [
    "***Create training dataset to predict time ahead: 1h, 4h, 8h, 12h, 16h, 24h***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880dcccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, y1_train, X1_test, y1_test = build_dataset(1)\n",
    "X4_train, y4_train, X4_test, y4_test = build_dataset(4)\n",
    "X8_train, y8_train, X8_test, y8_test = build_dataset(8)\n",
    "X12_train, y12_train, X12_test, y12_test = build_dataset(12)\n",
    "X16_train, y16_train, X16_test, y16_test = build_dataset(16)\n",
    "X20_train, y20_train, X20_test, y20_test = build_dataset(20)\n",
    "X24_train, y24_train, X24_test, y24_test = build_dataset(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27770247",
   "metadata": {},
   "source": [
    "## 4. Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5078a9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf40f00",
   "metadata": {},
   "source": [
    "***Create simple XGBoost model for corresponding dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3197c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred(pred, label):\n",
    "    p1_df = pd.DataFrame({'pred': pred, 'label': label, 'time': list(range(len(pred)))})\n",
    "    fg, ax = plt.subplots(figsize=(10,10))\n",
    "    sns.lineplot(data=p1_df, x='time', y='pred', label=\"pred\")\n",
    "    sns.lineplot(data=p1_df, x='time', y='label', label=\"label\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"PM2_5 Concentration\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a62c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = xgb.XGBRegressor().fit(X1_train, y1_train)\n",
    "pred1 = model1.predict(X1_test)\n",
    "mean_absolute_error(pred1, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fdbabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred(pred1, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33029013",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = xgb.XGBRegressor().fit(X4_train, y4_train)\n",
    "pred4 = model4.predict(X4_test)\n",
    "mean_absolute_error(pred4, y4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b337f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred(pred4, y4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37b126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model8 = xgb.XGBRegressor().fit(X8_train, y8_train)\n",
    "pred8 = model8.predict(X8_test)\n",
    "mean_absolute_error(pred8, y8_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e791dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred(pred8, y8_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80185552",
   "metadata": {},
   "outputs": [],
   "source": [
    "model12 = xgb.XGBRegressor().fit(X12_train, y12_train)\n",
    "pred12 = model8.predict(X12_test)\n",
    "mean_absolute_error(pred12, y12_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b6dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred(pred12, y12_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a540097",
   "metadata": {},
   "outputs": [],
   "source": [
    "model24 = xgb.XGBRegressor().fit(X24_train, y24_train)\n",
    "pred24 = model24.predict(X24_test)\n",
    "mean_absolute_error(pred24, y24_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c8a5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred(pred24, y24_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea791fe",
   "metadata": {},
   "source": [
    "## 5. Explain the Results"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.13.8"
   }
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('pyg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "source_map": [
   12,
   16,
   22,
   37,
   65,
   69,
   72,
   78,
   82,
   88,
   90,
   94,
   98,
   102,
   107,
   112,
   115,
   119,
   138,
   141,
   147,
   152,
   155,
   159,
   163,
   168,
   172,
   180,
   189,
   193,
   195,
   199,
   202,
   206,
   210,
   214,
   216,
   220,
   224,
   235,
   239,
   247,
   251,
   254,
   258,
   269,
   275,
   279,
   285,
   289,
   295,
   299,
   305,
   309,
   315,
   317
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}